{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2166435b-5614-45f1-a1c3-4070d54aa24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchreid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchreid\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbase64\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchreid'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import math\n",
    "import time\n",
    "import requests\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "import shutil\n",
    "import logging\n",
    "import glob\n",
    "import copy\n",
    "logging.getLogger(\"ultralytics\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from ultralytics import YOLO\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from our_utils import *\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "#from unidepth.models import UniDepthV1, UniDepthV2\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    #model_v1 = UniDepthV1.from_pretrained(f\"lpiccinelli/{name}\")\n",
    "        \n",
    "    model_v2 = UniDepthV2.from_pretrained(f\"lpiccinelli/{name}\")\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    qwen = Qwen2_5_VLForConditionalGeneration.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\",torch_dtype=torch.bfloat16,attn_implementation=\"flash_attention_2\",device_map=\"cuda:2\",)\n",
    "    processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
    "    qwen.eval()\n",
    "    \n",
    "    pose = YOLO(\"yolo11m-pose.pt\", 0.15)\n",
    "    pose.to('cuda:2')\n",
    "    print(pose.device)\n",
    "    \n",
    "    dirs = [d for d in glob.glob(\"/gpfs/scratch/jmurrugarral/VBIG_dataset/jsons_step2/*\") if os.path.isfile(d)]\n",
    "\n",
    "    #print(dirs)\n",
    "    parts  = [\"Nose\", \"Left Eye\", \"Right Eye\", \"Left Ear\", \"Right Ear\", \"Left Shoulder\", \"Right Shoulder\",\"Left Elbow\",\"Right Elbow\",\"Left Wrist\",\"Right Wrist\",\"Left Hip\",\"Right Hip\",\"Left Knee\",\"Right Knee\",\"Left Ankle\",\"Right Ankle\"]\n",
    "    \n",
    "    for json_path2 in dirs[1:5]:\n",
    "\n",
    "        p = Path(json_path2)\n",
    "        current_dir = Path(str(p).replace(\"jsons_step2\", \"videos_frames\"))\n",
    "        current_dir = str(current_dir.with_suffix(\"\"))\n",
    "\n",
    "        with open(json_path2, \"r\") as f:\n",
    "            json_data_s2 = json.load(f)\n",
    "\n",
    "        json_data_s3 = copy.deepcopy(json_data_s2)\n",
    "\n",
    "        #print(json_data_s3)\n",
    "        for ind, frame in enumerate(json_data_s2['frames']):\n",
    "\n",
    "            #print(f'{current_dir}/{str(ind+1).zfill(5)}.jpeg')\n",
    "            image = cv2.imread(f'{current_dir}/{str(ind+1).zfill(5)}.jpeg')\n",
    "            for det_id, detection in enumerate(frame['detections']):\n",
    "                #if detection == {}:\n",
    "                #    continue\n",
    "\n",
    "                json_data_s3['body_parts'] = parts\n",
    "                track_id = int(detection['track_id'])\n",
    "                o1_x1, o1_y1, o1_x2, o1_y2 = map(int, detection['bbox'])\n",
    "                o1_mid = ((o1_x1+o1_x2)//2, (o1_y1+o1_y2)//2)\n",
    "            \n",
    "                opencv_frame = image[int(o1_y1):int(o1_y2),int(o1_x1):int(o1_x2)]\n",
    "                pil_frame = opencv_to_pil(opencv_frame)            \n",
    "                label = 'person'\n",
    "                rgb_tuple = (255, 0, 0)\n",
    "                \n",
    "                prob_male, answer_male = vqa_yes_prob(qwen, processor, pil_frame, 'Is the person a male?')\n",
    "                prob_female, answer_female = vqa_yes_prob(qwen, processor, pil_frame, 'Is the person a female?')\n",
    "                prob_child, answer_child = vqa_yes_prob(qwen, processor, pil_frame, 'Is the person a child?')\n",
    "                prob_nbin, answer_nbin = vqa_yes_prob(qwen, processor, pil_frame, 'Is the person non-binary?')\n",
    "        \n",
    "                person = np.array([prob_male, prob_female, prob_child, prob_nbin])\n",
    "                sex = 'unknown'\n",
    "                if np.argmax(person)   == 0:\n",
    "                    sex='male'\n",
    "                elif np.argmax(person) == 1:\n",
    "                    sex='female'\n",
    "                elif np.argmax(person) == 2:\n",
    "                    sex='child'\n",
    "                elif np.argmax(person) == 3:\n",
    "                    sex='non binary'\n",
    "\n",
    "                #print(sex)\n",
    "                    #draw_tracking(frame=image, bbox = detection['bbox'], label=label, color=rgb_tuple)\n",
    "\n",
    "                #plt.imshow(cv2.cvtColor(opencv_frame, cv2.COLOR_BGR2RGB))\n",
    "                #plt.show()\n",
    "            \n",
    "                pose_result = pose(opencv_frame)\n",
    "                direction, visible   = 'unknown', 'unknown'\n",
    "            \n",
    "                if len(pose_result[0].boxes) > 0:\n",
    "        \n",
    "                    confs = pose_result[0].boxes.conf.cpu().numpy()\n",
    "                    best_idx = confs.argmax()\n",
    "                    \n",
    "                    highest_conf_result = pose_result[0][best_idx:best_idx+1]            \n",
    "                    confidence = highest_conf_result.keypoints.conf\n",
    "                    \n",
    "                    values = highest_conf_result.keypoints.conf>0.3\n",
    "                    parts  = [\"Nose\", \"Left Eye\", \"Right Eye\", \"Left Ear\", \"Right Ear\", \"Left Shoulder\", \"Right Shoulder\",\"Left Elbow\",\"Right Elbow\",\"Left Wrist\",\"Right Wrist\",\"Left Hip\",\"Right Hip\",\"Left Knee\",\"Right Knee\",\"Left Ankle\",\"Right Ankle\"]\n",
    "                    n_val = values.cpu().detach().numpy()[0]\n",
    "                    #print(highest_conf_result)\n",
    "                    key_values = highest_conf_result.keypoints.conf.cpu().detach().numpy()[0]\n",
    "                    #print(highest_conf_result.keypoints.xy)\n",
    "                    pose_position = highest_conf_result.keypoints.xy.cpu().detach().numpy()[0]\n",
    "                    #print(pose_position)\n",
    "                    counts_points_body = np.sum(np.array(n_val[5:]))\n",
    "        \n",
    "                    if counts_points_body:\n",
    "                        visible = 'not occluded'\n",
    "                    else:\n",
    "                        visible = 'occluded'\n",
    "        \n",
    "                    if n_val[0] == True and n_val[1] == True and n_val[2] == True and n_val[3] == True and n_val[4] == True:\n",
    "                        direction = 'front'\n",
    "                    elif n_val[0] == True and n_val[1] == True and n_val[2] == True and n_val[3] == True and n_val[4] == False:\n",
    "                        direction = 'front right'\n",
    "                    elif n_val[0] == True and n_val[1] == True and n_val[2] == False and n_val[3] == True and n_val[4] == False:\n",
    "                        direction = 'front rright'\n",
    "                    elif n_val[0] == True and n_val[1] == True and n_val[2] == True and n_val[3] == False and n_val[4] == True:\n",
    "                        direction = 'front left'\n",
    "                    elif n_val[0] == True and n_val[1] == False and n_val[2] == True and n_val[3] == False and n_val[4] == True:\n",
    "                        direction = 'front lleft'\n",
    "                    elif n_val[0] == False and n_val[1] == False and n_val[2] == False and n_val[3] == True and n_val[4] == True:\n",
    "                        direction = 'back'\n",
    "                    elif n_val[0] == False and n_val[1] == False and n_val[2] == True and n_val[3] == True and n_val[4] == True:\n",
    "                        direction = 'back right'\n",
    "                    elif n_val[0] == False and n_val[1] == True and n_val[2] == False and n_val[3] == True and n_val[4] == True:\n",
    "                        direction = 'back left'\n",
    "\n",
    "                    json_data_s3['frames'][ind]['detections'][det_id]['xy_body_parts'] = pose_position.tolist()\n",
    "                    json_data_s3['frames'][ind]['detections'][det_id]['conf_body_parts'] = key_values.tolist()\n",
    "                #print(json_data_s3['frames'][ind]['detections'][det_id])\n",
    "                json_data_s3['frames'][ind]['detections'][det_id]['sex'] = sex\n",
    "                json_data_s3['frames'][ind]['detections'][det_id]['direction'] = direction\n",
    "                json_data_s3['frames'][ind]['detections'][det_id]['visible'] = visible\n",
    "                \n",
    "                #print(direction)\n",
    "\n",
    "        p2 = Path(json_path2)         \n",
    "        new_path2 = Path(str(p2).replace(\"jsons_step2\", \"jsons_step3\"))\n",
    "    \n",
    "        p3 = Path(new_path2)\n",
    "        json3_path = p3.parent\n",
    "\n",
    "        os.makedirs(json3_path, exist_ok=True)\n",
    "        with open(f\"{new_path2}\", \"w\") as fp: \n",
    "            json.dump(json_data_s3, fp, indent=4)\n",
    "\n",
    "        print(json_data_s3)\n",
    "\n",
    "            #print(frame['detections'][0])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a37fe24-2830-433e-aa9e-f6dc7cc8577a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 21 19:44:11 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:17:00.0 Off |                    0 |\n",
      "| N/A   46C    P0             83W /  300W |   80831MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A100 80GB PCIe          On  |   00000000:65:00.0 Off |                    0 |\n",
      "| N/A   53C    P0             90W /  300W |   81081MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A100 80GB PCIe          On  |   00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   43C    P0             80W /  300W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A100 80GB PCIe          On  |   00000000:E3:00.0 Off |                    0 |\n",
      "| N/A   41C    P0             65W /  300W |       4MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A          997605      C   ...3/envs/py10-videos/bin/python      80822MiB |\n",
      "|    1   N/A  N/A          997605      C   ...3/envs/py10-videos/bin/python      81072MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905ca58-5f1c-4594-83f8-bfbd8b671f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
