{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "315226d0-0333-416c-8c56-9235ba9c14b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulk_process_1/Antananarivo_Madagascar - Antananarivo Madagascar walking tour [Antananarivo Madagascar walking tour] - [oVuj3mueH2o]\n",
      "bulk_process_1/Antananarivo_Madagascar - Antananarivo Madagascar walking tour [Antananarivo Madagascar walking tour] - [oVuj3mueH2o]/Antananarivo_001_0003.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4014390/1627651730.py:30: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colormap = plt.cm.get_cmap(\"tab20\", 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2-4': 1, '8-9-10': 1, '2-4-6': 1, '2-9': 2, '20-22': 2, '2-12': 4, '3-90': 7, '88-89': 4, '87-95': 1, '3-90-99': 4, '87-98': 2, '88-89-103': 2, '12-88-103': 2, '87-90-99': 4, '87-99': 4, '3-87-90-99': 1, '89-109': 3, '116-117': 1, '87-90': 3, '3-87-90': 5, '89-140': 1, '99-116-133-144': 2, '99-133': 1, '99-116-133': 1}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import networkx as nx\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "from our_utils import *\n",
    "\n",
    "video_name = 'bulk_process_1/Antananarivo_Madagascar - Antananarivo Madagascar walking tour [Antananarivo Madagascar walking tour] - [oVuj3mueH2o]'\n",
    "\n",
    "print(video_name)\n",
    "\n",
    "pattern = glob.escape(video_name) + \"/*.json\"\n",
    "file = glob.glob(pattern)\n",
    "file.sort()\n",
    "#print(file)\n",
    "file = file[2]\n",
    "print(file)\n",
    "\n",
    "with open(f\"{file}\", \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "    \n",
    "cmap = plt.get_cmap(\"tab20\")\n",
    "colormap = plt.cm.get_cmap(\"tab20\", 20)\n",
    "\n",
    "N = 20\n",
    "colors = [cmap(i) for i in range(N)]\n",
    "palette = (np.array(colors)[:, :3] * 255).astype(np.uint8)\n",
    "\n",
    "hash_table = {}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "video_path = data['path'] # UPDATED\n",
    "#print(video_path)\n",
    "cap = cv2.VideoCapture(video_path) # UPDATED\n",
    "spacing  = data['spacing'] # UPDATED\n",
    "\n",
    "toProcess = data['frames']\n",
    "\n",
    "for ind, frame_data in enumerate(toProcess):\n",
    "    \n",
    "    frame_id = frame_data['frame_id']\n",
    "    detections = frame_data['detections']\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id*spacing) # UPDATED\n",
    "\n",
    "    ret, image = cap.read()    \n",
    "    frame = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    coord3 = np.zeros((1000,image.shape[1],3),dtype=np.uint8)+255\n",
    "    coord2 = np.zeros((1000,1000,3),dtype=np.uint8)+255\n",
    "    coord1 = np.zeros((1000,image.shape[1],3),dtype=np.uint8)+255\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    #G.add_edges_from(edges)\n",
    "\n",
    "    ### UPDATED ####\n",
    "    \n",
    "    components = frame_data.get(\"components_60\", [])\n",
    "    for comp in components:\n",
    "        for i in range(len(comp)):\n",
    "            for j in range(i + 1, len(comp)):\n",
    "                G.add_edge(comp[i], comp[j])\n",
    "    \n",
    "    ### UPDATED ####\n",
    "    \n",
    "    groups = np.arange(1000)\n",
    "    for idx, comp in enumerate(components, 1):\n",
    "        \n",
    "        key = \"-\".join(str(c) for c in comp)\n",
    "        for c in comp:\n",
    "            groups[c] = idx\n",
    "\n",
    "        if key not in hash_table:\n",
    "            hash_table[key]=1\n",
    "        else:\n",
    "            hash_table[key]+=1\n",
    "\n",
    "    for n in G.nodes():\n",
    "        G.nodes[n]['pos'] = (0,0)\n",
    "        \n",
    "    for int_id, det in enumerate(detections):\n",
    "        \n",
    "        x1, y1, x2, y2 = map(int, det['bbox'])\n",
    "        track_id = det['track_id']\n",
    "        #print(track_id)\n",
    "        class_name = 'person'\n",
    "        label = f\"{class_name} ID:{track_id}\"\n",
    "        rgb_tuple = (int(palette[track_id%20][0]),int(palette[track_id%20][1]),int(palette[track_id%20][2]))\n",
    "\n",
    "        o1_mid = ((x1+x2)//2, (y1+y2)//2) # updated\n",
    "        d1 = int(det['depth']) # updated\n",
    "        \n",
    "        X, Y, Z = det['3D_60FOV']\n",
    "\n",
    "        h1, w1 = coord1.shape[:2]\n",
    "        h2, w2 = coord2.shape[:2]\n",
    "        h3, w3 = coord3.shape[:2]\n",
    "\n",
    "        center1 = (int((X+2)*100), 1000-int(Z*100)) # updated\n",
    "        center2 = (int((X+2)*100), int(d1)*4) # updated\n",
    "        center3 = (int(o1_mid[0]), int(d1)*4) # updated\n",
    "        \n",
    "        direction = det['direction']\n",
    "        offset = 25\n",
    "        \n",
    "        plot_coord(coord1, center1, direction, offset, rgb_tuple)\n",
    "        plot_coord(coord2, center2, direction, offset, rgb_tuple)\n",
    "        plot_coord(coord3, center3, direction, offset, rgb_tuple)\n",
    "        \n",
    "        if class_name == 'person':\n",
    "            draw_tracking(frame=image, bbox = det['bbox'], label=label, color=rgb_tuple)\n",
    "            \n",
    "        #print(G.nodes)\n",
    "        if track_id in G.nodes:\n",
    "            G.nodes[track_id]['pos'] = (int(o1_mid[0]), -int(d1)*4)\n",
    "        #else:\n",
    "        #    G.nodes[track_id]['pos'] = (0,0)\n",
    "        #node_positions[track_id] = center3\n",
    "\n",
    "    \n",
    "        \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    coord1 = cv2.cvtColor(coord1, cv2.COLOR_BGR2RGB)\n",
    "    coord2 = cv2.cvtColor(coord2, cv2.COLOR_BGR2RGB)\n",
    "    coord3 = cv2.cvtColor(coord3, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    pos = nx.get_node_attributes(G, \"pos\")\n",
    "\n",
    "    #pos = nx.spring_layout(G, seed=42)\n",
    "        \n",
    "    node_colors = [colormap(n%20) for n in G.nodes()]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    nx.draw(\n",
    "        G, pos, ax=ax,\n",
    "        with_labels=True,\n",
    "        node_color=node_colors,\n",
    "        edge_color=\"gray\",\n",
    "        node_size=100  \n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    graph = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "    graph = graph.reshape(fig.canvas.get_width_height()[::-1] + (4,))  # 4 channels\n",
    "    graph = graph[:,:,:3]\n",
    "    graph = cv2.cvtColor(graph, cv2.COLOR_BGR2RGB)\n",
    "    plt.close(fig)\n",
    "\n",
    "    combined_frame1 = np.hstack([cv2.resize(image, (600, 320)), cv2.resize(coord2, (600, 320))])    \n",
    "    combined_frame2 = np.hstack([cv2.resize(coord3, (600, 320)), cv2.resize(graph, (600, 320))])\n",
    "    combined_frame = np.vstack([combined_frame1, combined_frame2])\n",
    "\n",
    "    plt.figure(figsize=(36, 8))\n",
    "    plt.imshow(combined_frame)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Frame {ind}\")\n",
    "    plt.show()\n",
    "\n",
    "cap.release()    \n",
    "print(hash_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa77ce63-70f0-4dd4-a4b8-bdb4ef026485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3-90', 7), ('3-87-90', 5), ('2-12', 4), ('88-89', 4), ('3-90-99', 4), ('87-90-99', 4), ('87-99', 4), ('89-109', 3), ('87-90', 3), ('2-9', 2), ('20-22', 2), ('87-98', 2), ('88-89-103', 2), ('12-88-103', 2), ('99-116-133-144', 2), ('2-4', 1), ('8-9-10', 1), ('2-4-6', 1), ('87-95', 1), ('3-87-90-99', 1), ('116-117', 1), ('89-140', 1), ('99-133', 1), ('99-116-133', 1)]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of groups to visualize:  4\n"
     ]
    }
   ],
   "source": [
    "posible_groups = sorted(hash_table.items(), key= lambda item:item[1], reverse=True)\n",
    "print(posible_groups)\n",
    "\n",
    "def draw_raw(frame, detection):\n",
    "    x1, y1, x2, y2 = map(int, detection)\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (255,0,0) , 2)\n",
    "    cv2.putText(frame, 'person', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "    \n",
    "with open(f\"{file}\", \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "    \n",
    "frames = data['current_total_frames']\n",
    "spacing = data['spacing']\n",
    "\n",
    "n = int(input(\"Enter number of groups to visualize: \"))\n",
    "\n",
    "first_ids_str, _ = posible_groups[0]\n",
    "max_frames = 40\n",
    "\n",
    "rows = int(math.sqrt(n))\n",
    "cols = int(math.ceil(n/rows))\n",
    "group_frames = []\n",
    "\n",
    "for group_idx, (ids_str, _) in enumerate(posible_groups[:n]):\n",
    "    \n",
    "    ids = [int(x) for x in ids_str.split('-')]\n",
    "    cap = cv2.VideoCapture(data['path'])\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, data['start_frame'])\n",
    "    c_frames = 0\n",
    "    frame = 0\n",
    "    j = 0\n",
    "    saved_images = []\n",
    "\n",
    "    while c_frames < (frames-1)*spacing and len(saved_images) < max_frames:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        if c_frames % spacing == 0:\n",
    "            track_ids = [det['track_id'] for det in data['frames'][j]['detections']]\n",
    "            show = False\n",
    "            for idx in ids:\n",
    "                if idx in track_ids:\n",
    "                    ind = track_ids.index(idx)\n",
    "                    draw_raw(frame, data['frames'][j]['detections'][ind]['bbox'])\n",
    "                    show = True\n",
    "            if show:\n",
    "                saved_images.append(cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB),(0, 0), fx=0.5, fy=0.5))\n",
    "            j += 1\n",
    "\n",
    "        c_frames += 1\n",
    "    cap.release()\n",
    "\n",
    "    while len(saved_images) < max_frames:\n",
    "        if saved_images:\n",
    "            saved_images.append(np.zeros_like(saved_images[0]))    \n",
    "    group_frames.append(saved_images)\n",
    "    \n",
    "rows = int(math.sqrt(n))\n",
    "cols = int(math.ceil(n / rows))\n",
    "\n",
    "for frame_idx in range(max_frames):\n",
    "    grid_image = np.vstack([\n",
    "        np.hstack([\n",
    "            group_frames[r * cols + c][frame_idx] if r * cols + c < len(group_frames)\n",
    "            else np.zeros_like(group_frames[0][0]) #np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "            for c in range(cols)\n",
    "        ])\n",
    "        for r in range(rows)\n",
    "    ])\n",
    "    \n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.imshow(grid_image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Frame {frame_idx+1} of {max_frames}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeece2f-7c9a-42a8-992f-5ab2107e95a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
